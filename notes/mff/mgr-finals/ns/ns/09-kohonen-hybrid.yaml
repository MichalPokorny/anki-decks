deck: All::Magisterské státnice::Neuronové sítě::Přednáška 9 (Kohonenovy sítě a hybridní sítě)
notes:
        # 09-kohonen-hybrid
        -
                uuid: adc2c3cf-9d46-4ac2-aff4-e616686aee7c
                topic: Kononenova mapa
                front: >
                        Účel, parametry
                back: >
                        Učení bez učitele.<br>
                        Najdi topologické okolí nejbližšího neuronu a taky ho
                        uprav.<br>
                        Funkce laterální interakce: [$]\\Phi(i,k)[/$],
                        například "funkce mexického klobouku"<br>
                        Vigilační koeficient [$]\\alpha\\in(0;1)[/$] určuje plasticitu, klesá v čase.
        -
                uuid: 964a216b-1159-4e20-840a-e79d82a64e67
                topic: Kononenova mapa
                front: Co by mělo platit pro vigilační koeficient?
                markdown: false
                back: >
                        [$]\sum_{t=1}^\infty \alpha(t)=\infty, \sum_{t=1}^\infty \alpha^2(t) < \infty[/$]
        -
                uuid: 6d368fb6-973e-465d-8a2d-30bea1c20260
                topic: Kononenova mapa
                front: >
                        Kostra důkazu: Jeden neuron Kohonenovy mapy na intervalu
                        [$][a;b][/$] se ustálí ve středu
                back: >
                        Adaptační pravidlo: [$]w_n\\leftarrow w_{n-1}+\\eta(x-w_{n-1})[/$],
                        kde [$]x[/$] je náhodně zvolené z [$][a,b][/$].
                        Pro [$]\\eta\\in(0;1)[/$] nemůže [$]w[/$] opustit [$][a,b][/$]<br>

                        Ocekavana hodnota [$]\\mathbb{E}[dx/dt][/$] musi byt 0,
                        jinak by mohlo byt [$]\\mathbb{E}[x]\\notin [a;b][/$].<br>

                        [$$]\\mathbb{E}[dx/dt]=\\eta(\\mathbb{E}[x]-\\mathbb{E}[w])=
                        \\eta((a+b)/2 - \\mathbb{E}[x]) = 0 \\longrightarrow \\mathbb{E}[w]=(a+b)/2[/$$]
        -
                uuid: 69a572dd-fa8e-40b6-9367-29d8a18c7d99
                topic: Kononenova mapa
                front: Varianty učících algoritmů pro učení s učitelem pro Kohonenovy mapy
                back: >
                        <ul>
                        <li>
                        LVQ1: [$]x[/$] by mělo patřit ke stejné třídě jako
                        nejbližší [$]w_i[/$].<br>

                        Vezmi nejbližší neuron, když je klasifikovaný stejně,
                        přibliž ho, kryž různě, oddal ho. S ostatními neurony
                        nehýbej.
                        <li>
                        LVQ2.1: Adaptuj 2 nejbližší sousedy současně. Jeden
                        z nich musí patřit ke správné třídě, druhý k nesprávné.
                        Když je [$]x[/$] z okenka mezi [$]w_i[/$], [$]w_j[/$] a
                        ty neurony maji ruzne tridy, tak spravny neuron prisun
                        a spatny odsun.<br>
                        Okenko: [$]\\min(\\frac{d_i}{d_j}, \\frac{d_j}{d_i})>\\frac{1-s}{1+s}[/$],
                        kde [$]s[/$] je sirka okenka, treba [$]0.2[/$] az [$]0.3[/$]
                        <li>
                        LVQ3: Plus: jestlize [$]w_i[/$] i [$]w_j[/$] patri do
                        stejne tridy, tak je prisun
                        o [$]\\varepsilon \\alpha(t)[x(t)-w_{i/j}(t)][/$], kde [$]0.1\\leq\\varepsilon\\leq 0.5[/$]
                        </ul>
        -
                uuid: 45896e39-ff1f-4efc-a55e-309f100f71ff
                front: >
                        Jméno: Vrstva nad Kohonenovskou
                        v counterpropagation sítích
                back: Grossbergovská
        -
                uuid: 56e732ce-9373-44b0-9d81-7c6cb3d4561a
                front: Sítě se vstřícným šířením (counterpropagation) - architektura, učení
                back: >
                        2 vrstvy: Kohonenovská, Grossbergovská (adaptuje váhy
                        jen pro vítěze z Kohonenovy vrstvy).
                        Použití: heteroasociativní paměť.<br>

                        <ol type="1">
                        <li> Vyber nejblizsi neuron v Kohonenovské vrstvě
                        <li> Aktualizuj vahy v Kohonenovske vrstve
                        <li> Uprav vahy mezi "vitezem" [$]c[/$] z Kohonenovy
                             vrstvy a neurony Grossbergovske vrstvy, aby vystup
                             odpovidal vic ocekavane odezve [$]d[/$]:
                             <br>
                             [$$]w_{cj} \\leftarrow (1-\\beta)w_{cj} + \\gamma z_c d_j[/$$]
                             <br>
                             Kde [$]\\beta>0, \\gamma>0, z_c[/$] je aktivita
                             viteze z Kohonenovske vrstvy
                        </ol>
        -
                uuid: e8b48098-6b46-4500-8fc9-d7e816888ce9
                topic: RBF sítě
                front: Definice RBF funkce a co ta zkratka znamená
                back: >
                        Radial Basis Functions.<br>
                        [$$]RBF(x,w,\\sigma) := \\exp\\{-\\frac{(x-w)^2}{2\\sigma^2}\\}[/$$]
        -
                uuid: fa514eee-0607-4206-af82-7df4be2c1dd3
                topic: RBF sítě
                front: Jakou mají architekturu?
                back: >
                        Vstup &rarr; Kohonenovská vrstva s Gaussovskou
                        přenosovou funkcí &rarr; lineární asociátor &rarr;
                        skalární výstup
        -
                uuid: b59d1818-0ec4-4305-8bb3-f8a90582d92a
                topic: RBF sítě
                front: Jak počítá?
                back: >
                        Neuron [$]j[/$] počítá výstup
                        [$]g_j(x)=RBF(x, w_j, \\sigma_j) / \\sum_k RBF(x, w_k, \\sigma_k)[/$].<br>

                        [$]\\sigma_i[/$] jsou konstanty: například nastavené podle vzdálenosti mezi váhovým vektorem a jeho nejbližším sousedem<br>

                        Z RBF vrstvy vedou váhy [$]z_1\\ldots z_m[/$].<br>
                        Ty jdou nastavit třeba zpětným šířením.
        -
                uuid: af99f342-72d2-4801-a35a-bbfb0fdde854
                topic: RBF sítě
                front: >
                        Jak nastavit váhy [$]z_i[/$] z Kohonenovských neuronů
                        k lineárnímu asociátoru?
                back: >
                        [$]
                        E=\\frac{1}{2}\\sum_p (\\sum_{i=1}^n g_i(x_p)z_i - d_p)^2
                        [/$]<br>

                        [$]
                        \\Delta z_i \\approx -\\partial E/\\partial z_i =
                        \\gamma g_i(x) (d - \\sum_{j=1}^n g_j(x) z_j)
                        [/$]
        -
                uuid: a4eb55d5-10de-44d4-8d2f-5b91d7f334cd
                topic: ART
                front: Architektura, jaké je kódování
                back: >
                        2 vrstvy: vstupní, výstupní.<br>

                        Vstupy: binární. Učí se bez učitele.<br>

                        Spojení: vstupy &rarr; výstupy, výstupy &rarr; vstupy,
                        výstupy mezi sebou (ale bez smyček z neuronu zpět do
                        něj)<br>

                        Má mechanismus pro vypnutí výstupního neuronu
                        s maximální odezvou.
        -
                uuid: 64ce36aa-9f82-4884-a441-bf3e30442ce0
                topic: ART
                front: Účel laterálních spojů mezi výstupními neurony
                back: >
                        Určení výstupního neuronu s maximální odezvou.
        -
                uuid: 71e5a70b-2b14-4bc5-9d49-2ab94e9d5b24
                topic: ART
                front: Účel zpětných vazbeb z výstupů ke vstupům
                back: >
                        Porovnání skutečné podobnosti s rozpoznaným vzorem.
        -
                uuid: 9a6ebf84-2811-4df0-b661-578119600968
                topic: ART
                front: Problém
                back: >
                        I při troše šumu začne ukládat moc vzorů
        -
                uuid: 5cdea2dc-a1af-4f23-abc5-f5b50fae5643
                topic: ART
                front: Značení - váhy ze vstupu [$]i[/$] do výstupu [$]j[/$]
                back: >
                        [$]b_{ij}[/$]
                include_reverse: true
        -
                uuid: bf9305e1-c32f-4861-876b-4702cf317e59
                topic: ART &mdash; Značení
                front: Váhy z výstupu [$]j[/$] do vstupu [$]i[/$]
                back: >
                        [$]t_{ij}[/$]
                include_reverse: true
        -
                uuid: 17908552-6d39-43de-8c7c-4bba1fb61b9d
                topic: ART &mdash; Značení
                front: Výstupy výstupních neuronů
                back: >
                        [$]\\mu_j[/$]
                include_reverse: true
        -
                uuid: 179f5bf7-0dd8-42d5-b161-c607274db0de
                topic: ART
                front: Značení vah a parametrů, jejich inicializace
                back: >
                        <ul>
                        <li>
                        [$]t_{ij}(0) = 1[/$] (váhy z výstupu do vstupu &mdash;
                        vzor specifikovaný výstupním neuronem [$]j[/$])
                        <li>
                        [$]b_{ij}(0)=1 / (1+N)[/$] (váhy ze vstupu do výstupu)
                        <li>
                        [$]\\rho\\in[0;1][/$] &mdash; jak blízko musí být vstup
                        k uloženému vzoru, aby byl ve stejné kategorii.
                        <li>
                        Výstupy výstupních neuronů: [$]\\mu_j[/$]
                        </ul>
        -
                uuid: 5dde3276-aa9f-48f6-bc31-ee7b4c40eb7a
                topic: ART &mdash; Značení
                front: Konstanta bdělosti
                back: >
                        [$$]\\rho\\in[0;1][/$$]
                include_reverse: true
        -
                uuid: ae99b9ea-f197-41ae-a9ca-e08804981b66
                topic: ART
                front: Učící algoritmus
                back: >
                        <ul>
                        <li> Předlož nový vstup [$]x[/$].
                        <li> Spočítej výstupy:
                             [$]\\mu_j = \\sum_{i=1}^{N} b_{ij}(t) x_i[/$]
                        <li> Vyber nejbližší odpovídající vzor:
                             [$]j^{ * } \\leftarrow \\arg\\max_j\\{\\mu_j\\}[/$]
                        <li> Test bdělosti:
                             [$]\\|x\\|=\\sum_i x_i,
                                \\|T\\cdot x\\|=\\sum_i t_{ij} \\cdot x_i[/$]
                             <br>
                             Když [$]\\frac{\\|T\\cdot x\\|}{\\|x\\|}<\\rho[/$],
                             dočasně nastav [$]\\mu_{j^{ * }}\\leftarrow 0[/$],
                             znova vyber nejlepší neuron bez účasti
                             [$]j^{ * }[/$].
                        <li> Aktualizace nejlépe odpovídajícího neuronu:
                             [$]t_{ij^{ * }}(t+1) = t_{ij^{ * }}(t) \\cdot x_i[/$],
                             [$]b_{ij^{ * }}(t+1) =
                             \\frac{t_{ij^{ * }} \\cdot x_i}
                                   {0.5 + \\sum_{k=0}^{N-1} t_{kj^{ * }}(t) \\cdot x_k}
                             [/$]
                        <li> Odmraž a opakuj.
                        </ul>
        -
                uuid: bfffc115-79e0-4ac9-afe0-4c70be3876b1
                front: Kaskádová korelace, algoritmus učení
                markdown: true
                back: >
                        Začnu s přímým propojením vstupů na výstup.<br>
                        Přidávám skryté neurony.<br>
                        Vstupy nového jsou propojeny se všemi
                        předchozími vstupy a výstupy dřívějších neuronů.
                        <ol type="1">
                        <li> Adaptuj existující síť QuickPropem.
                             Když je malá chyba, konči.
                        <li> Přidej neuron, co maximalizuje korelaci svého
                             výstupu s chybou sítě. V další iteraci zmraž váhy
                             jeho vstupů, douč váhu jeho výstupů.
                        </ul>
                        Maximalizuj:
                        [$]S\equiv |\sum_{i=1}^p (V_i-\overline{V})(E_i-\overline{E})|[/$]
                        <br>
                        [$]V_i[/$]: výstup nového neuronu na vzoru [$]i[/$],
                        [$]\overline{V}[/$]: průměrný výstup nového
                        neuronu, to samé chyba
                        <br>
                        [$]\partial S/\partial w_k = \sum_p \delta_p I_{pi}[/$],
                        kde:
                        <br>
                        [$]\delta_p = \sum_o \sigma_o(e_{po}-\overline{e_j})f'_p[/$]
                        <br>
                        [$]\sigma_o[/$]: znaménko korelace mezi novým
                        neuronem a reziduální chybou na výstupu [$]o[/$]<br>
                        [$]f'_i[/$]: derivace přenosové funkce ve výstupní
                        jednotce<br>
                        [$]I_{pi}[/$]: [$]i[/$]-tý vstup nového neuronu pro
                        vzor [$]p[/$]
