uid_tag: math
deck: All::Math
notes:
        -
                uuid: 5c64ac78-bc43-4821-9084-f2bf98e6c320
                front: Logistic function
                back: AKA sigmoid. [$]f(x)=(1+e^{-\lambda x})^{-1}[/$]
        -
                uuid: 8b422f19-b1a6-4853-ae6c-c373e8daa591
                front: Wedderburn theorem
                back: Every finite field is commutative
        -
                uuid: ebca1d61-11bf-48b7-a21b-5733e28e5dc9
                front: BBP-type formula
                back:
                        Bailey-Borwein-Plouffe formula. Computes n-th binary digit of pi using base 16 math.
                        Can directly calculate some digit of pi without calculating preceding digits.
                        Since this discovery, many formulas for other irrational constants have been discovered of the general form.
                        Formulas in this form are known as BBP-type formulas.
                        [$$]
                        \pi = \sum_{k = 0}^{\infty}\left[ \frac{1}{16^k} \left( \frac{4}{8k + 1} - \frac{2}{8k + 4} - \frac{1}{8k + 5} - \frac{1}{8k + 6} \right) \right]
                        [/$$]

                        https://wikimedia.org/api/rest_v1/media/math/render/svg/af6bc360851499dd2ab2a90bee03fbe2040089d5
        -
                uuid: 5cb921d7-535c-441f-b074-78cdabe4d336
                front: Skolem paradox
                back: ZF set theory has a countable model
                include_reverse: true
        -
                uuid: 6db03c44-0ad5-4d37-b4e0-55ade1ec116f
                front: Goodstein theorem
                back: Statement about natural numbers which states that every Goodstein sequence eventually terminates at 0. Unprovable in Peano arithmetic, but can be proven in stronger systems, e.g. second order arithmetic.
        -
                uuid: 40ea1145-01bf-4d44-856a-2c36f8bdfd89
                front: Brouwer theorem
                back: "Brouwer fixed-point theorem: for any continuous f mapping a compact convex set into itself has a fixed point"
# TODO: Kegan's stages
        -
                uuid: eea9aac1-ad18-4f44-83ca-a2336da27940
                front: Vapnik-Chervonenkis dimension
                back: >
                        Ať je [$]C=\\{f_i\\}[/$] množina funkcí (concept class).
                        Množina [$]m[/$] vzorů [$]\\{t_1,\\ldots t_m\\}[/$]
                        jde rozčlenit pomocí [$]C[/$], jestli existuje pro každé z 0/1 označení, kterých je [$]2^m[/$], existuje aspoň jedna funkce [$]f_i[/$] která mu vyhovuje.

                        VC-dimenze [$]V[/$] množiny funkcí [$]C[/$] je největší
                        [$]m[/$], pro které existuje množina [$]m[/$] rozčlenitelných trénovacích vzorů.

                        Je-li VC dimenze nekonečná, je to nenaučitelné.

                        Neuronová síť může mít hodně parametrů, ale měla by mít malou VC dimenzi. Velká VC dimenze znamená horší generalizaci.

                        Příklad: VC-dimenze lineárních funkcí v [$]n[/$]-rozměrném prostoru je [$]n+1[/$] (víc jich rozdělit nejde).
                        Příklad: VC-dimenze sinusovek s libovolnou periodou je nekonečno
        -
                uuid: d8dfb615-f927-4284-a746-c3fa7e21bc46
                front: Definice pseudoinverzní matice
                back: >
                        [$]X \\hat{X} X = X, \\hat{X} X \\hat{X} = \\hat{X}, \\hat{X} X[/$] a [$]X \\hat{X}[/$] jsou symetricke.
                        Vzdy existuje a je jednoznacne urcena.
        -
                uuid: 2de3f4b6-ac7d-400a-be6d-d08aadf7f53b
                front: Věta co minimalizuje pseudoinverzní matice, důkaz
                back: >
                        Ať je [$]X\\in\\R^{m\\times n}, Y\\in\\R^{m\\times k}[/$]. Pak [$]W=\\hat{X} Y[/$] minimalizuje [$]\\|XW-Y\\|^2[/$].<br>

                        Zároveň [$]\\hat{X}[/$] minimalizuje [$]\\|X\\hat{X}-I\\|^2[/$].<br>

                        [$]E:=\\|XW-Y\\|^2[/$]<br>

                        Dá se vyjádřit jako [$]E=tr(S)[/$], kde [$]S=(XW-Y)^T (XW-Y)[/$]<br>

                        [$$]
                        (XW-Y)^T (XW-Y) = (Y-XW)^T (Y-XW) = (-XW)^T (Y-XW) + Y^T(-XW) + Y^T Y =
                        [/$$]
                        [$$]
                        = (-XW)^T (Y-XW) + Y^T X \\hat{X} (Y-XW) + Y^T(I-X\\hat{X})Y =
                        [/$$]
                        [$$]
                        = (X\\hat{X}Y-XW)^T (Y-XW) + Y^T (I-X\\hat{X})Y =
                        [/$$]
                        [$$]
                        = (\\hat{X}Y-W)^T X^T (Y-XW)+Y^T(I-X\\hat{X})Y =
                        [/$$]
                        [$$]
                        = (\\hat{X}Y-W)^T (X^T Y-X^T XW)+Y^T(I-X\\hat{X})Y =
                        [/$$]
                        [$$]
                        = (\\hat{X}Y-W)^T ((X\\hat{X}X)^T Y-X^T XW)+Y^T(I-X\\hat{X})Y =
                        [/$$]
                        [$$]
                        = (\\hat{X}Y-W)^T (X^T X\\hat{X}Y-X^T XW)+Y^T (I-X\\hat{X})Y =
                        [/$$]
                        [$$]
                        = (\\hat{X}Y-W)^T X^T X(\\hat{X}Y-W)+Y^T(I-X\\hat{X})Y
                        [/$$]

                        Tedy:
                        [$$]
                        E=tr((\\hat{X}Y-W)^T X^T X (\\hat{X}Y-W)) + tr(Y^T (I-X\\hat{X}) Y)
                        [/$$]

                        To vpravo je konstanta. To vlevo je minimální pro [$]W=\\hat{X}Y[/$].

